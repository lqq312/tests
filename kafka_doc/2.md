# kafka快速入门

kafka的安装依赖于java环境，目前kafka_2.12-0.10.2.1的版本要求使用jdk-1.8.0的版本。

kafka是使用二进制安装，解压后修改配置文件即可运行。

## 安装部署

### zookeeper配置文件

    tickTime=2000：它用来控制心跳和超时(毫秒)；
    initLimit=10：Follower连接到主节点初始化时间；
    syncLimit=5：主从节点请求和应答时间长度；
    dataDir=/usr/local/zookeeper/data：用于存储zookeeper产生的数据；
    dataLogDir=/usr/local/zookeeper/logs：定义zookeeper服务产生的日志；
    clientPort=2181：定义zookeeper监听端口；
    server.1=192.168.3.190:2888:3888：zookeeper节点名称以服务以及服务所用端口，所有节点依次列举

### kafka配置文件

kafka的配置文件包括：

    connect-console-sink.properties
    connect-console-source.properties
    connect-distributed.properties
    connect-file-sink.properties
    connect-file-source.properties
    connect-log4j.properties
    connect-standalone.properties
    consumer.properties：用于命令行的消费者的配置信息，主要用于测试。
    log4j.properties：
    producer.properties：用于命令行的生产者的配置信息。
    server.properties：kafka运行所需要的主配置文件。
    tools-log4j.properties
    zookeeper.properties：kafka自带的zookeeper的配置文件，不一定非要使用其自带的zookeeper，在kafka集群内只要有zookeeper可用即可。

server.properties：

    broker.id=131：定义kafka集群内各节点的id号，各节点的id不重复，且id号仅能使用整数，一般建议使用ip地址的主机位的数字。
    delete.topic.enable=true：定义是否允许删除topic，默认不允许删除。
    listeners=PLAINTEXT://192.168.3.131:9092：定义该主机的kafka监听器的类型、ip和端口。
    advertised.listeners=PLAINTEXT://192.168.3.131:9092：指定广播给生产者、消费者的监听器、ip和端口。
    num.network.threads=3：用来处理网络请求的网络线程数目。
    num.io.threads=20：broker处理磁盘I/O的线程数，这个线程数目至少要等于硬盘的个数。
    socket.send.buffer.bytes=102400：SO_SNDBUFF发送缓存大小，server进行socket连接所用。
    socket.receive.buffer.bytes=102400：SO_RCVBUFF接收缓存大小，server进行socket连接时所用。
    socket.request.max.bytes=104857600：server允许的最大请求尺寸；这将避免server溢出，它应该小于Java heap size。
    log.dirs=kafka-logs：定义kafka保存在要地的数据目录的位置。
    num.partitions=1：定义topic的分区的数量，如果创建topic时没有给出划分partitions个数，这个数字将是topic下partitions数目的默认数值。；
    num.recovery.threads.per.data.dir=1：每个数据目录用来日志恢复的线程数目。
    log.flush.interval.messages=10000：log文件“sync”到磁盘之前累积的消息条数。
    log.flush.interval.ms=1000：log文件”sync”到磁盘时间间隔。
    log.cleanup.policy = delete：日志清除策略。
    log.retention.hours=30：数据保存的本地时长（单位小时）。
    log.retention.bytes=10737418240：一个基于大小的日志保留策略。段将被从日志中删除只要剩下的部分段不低于log.retention.bytes。
    log.segment.bytes=1073741824：定义单个数据文件最大的大小，当存储的数据超过这个大小时则会创建一个新的数据文件用于存放消息。
    log.retention.check.interval.ms=300000：检查日志段的时间间隔，看是否可以根据保留策略删除它们。
    zookeeper.connect=kafka1:2181,kafka2:2181,kafka3:2181：定义kafka要使用的zookeeper集群内各节点的对应信息。
    zookeeper.connection.timeout.ms=6000：Zookeeper连接超时时间。

### kafka常用命令

kafka-console-consumer.sh：在命令行下交互式操作kafka的消费者。
    --topic <STRING>：指定topic的名称；
    --broker-list NODE1:9092：指定kafka集群中的节点；

    `bin/kafka-console-consumer.sh --topic text1 --bootstrap-server kafka1:9092`

***即可进入交互式模式，从而在交互式的接口下输入的消息即会传送到消息队列中。***

    `bin/kafka-console-consumer.sh --topic text1 --bootstrap-server kafka1:9092 --from-beginning`

***在交互式模式下从指定topic的开头处接收消息。***

kafka-console-producer.sh：在命令行下交互式操作kafka的生产者。
    --topic \<STRING>：指定topic的名称；
    --bootstrap-server NODE1:9092：指定kafka集群中的节点；
    --from-beginning：指定从开始处接收消息；

    `bin/kafka-console-producer.sh --topic text1 --broker-list kafka1:9092`

***在交互式模式下实时接收指定topic的消息。***

kafka-consumer-perf-test.sh

kafka-producer-perf-test.sh

kafka-topics.sh：kafka的topic的管理（增删改查）。
    --zookeeper：指定zookeeper集群的服务地址（仅指定zookeeper中的一个节点即可）；
    --list：列出所有topic；
    --describe：列出topic的详情，如不使用--topic选项则会列出所有topic的详细信息；
    --create：用于创建一个topic；
    --replication-factor：定义当前topic的副本数（包括Leader和Follower的总数，但不能超过broker的数量）；
    --partitions：定义分区数（如一个topic指定多个分区，在数据目录下会以topic-#的形式显示多个分区目录）；
    --topic \<STRING>：指定topic的名称；
    --delete：删除指定的topic；

* 列出当前kafka集群中的所有topic

    `bin/kafka-topics.sh --zookeeper kafka1:2181 --list`

* 列出当前kafka集群中的指定topic的详情

    `bin/kafka-topics.sh --zookeeper kafka1:2181 --describe  --topic yisa`

![](/Users/luqq/Documents/02_tec-doc/kafka_doc/pic/2.1.png)

详细信息中包含有分区数、副本数、Leader的数量

* 向当前kafka集群中增加一个topic

    `bin/kafka-topics.sh --zookeeper kafka1:2181 --create --replication-factor 3 --partitions 1 --topic first`

* 在当前kafka集群中删除指定的topic（如需真正删除topic需要在配置文件中定义delete.topic.enable=true，否则只会标记topic为删除）

    `bin/kafka-topics.sh --zookeeper kafka1:2181 --delete --topic first`

kafka-server-start.sh：启动kafka服务，但启动服务需要指定配置文件。
    -daemon：以守护进程的方式运行。

    `kafka-server-start.sh -daemon conf/server.properties`

***kafka启动后会在logs目录下生成服务日志，日志文件名为server.log。***

kafka-server-stop.sh



./kafka-consumer-groups.sh --bootstrap-server 10.168.2.65:9092 --list：列出所有的group

./kafka-consumer-groups.sh --bootstrap-server 10.168.2.65:9092 --group calculation --describe：查看指定group的消费的offset

./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list 192.168.3.142:9092 --topic T808-0200 --time -1

./kafka-run-class.sh kafka.tools.GetOffsetShell --broker-list 192.168.3.142:9092 --topic T808-0200 --time -2



./kafka-consumer-groups.sh --bootstrap-server 10.168.2.65:9092,10.168.2.66:9092,10.168.2.67:9092 --group 1 --describe 2>/dev/null | awk '/T808-0200-1/{print $5}' ： 查看指定topic的消费堆积情况



### kafka部署过程

kafka与zookeeper版本对应关系：

kafka版本 | zookeeper 版本 | springboot版本
- | - | -
kafka_2.12-2.4.0 | zookeeper-3.5.6.jar |
kafka_2.12-2.3.1 | zookeeper-3.4.14.jar | springboot2.2.2
kafka_2.12-2.3.0 | zookeeper-3.4.14.jar | springboot2.2.2
kafka_2.12-1.1.1 | zookeeper-3.4.10.jar |
kafka_2.12-1.1.0 | zookeeper-3.4.10.jar |
kafka_2.12-1.0.2 | zookeeper-3.4.10.jar |
kafka_2.12-1.0.0 | zookeeper-3.4.10.jar |
kafka_2.12-0.11.0.0 | zookeeper-3.4.10.jar |
kafka_2.12-0.10.2.2 | zookeeper-3.4.9.jar |
kafka_2.11-0.10.0.0 | zookeeper-3.4.6.jar |
kafka_2.11-0.9.0.0 | zookeeper-3.4.6.jar |



1. 安装java环境

**注意：kafka集群内的基础环境都一样。**

    ```
    # wget http://192.168.3.195/Softwares/jdk/jdk-8u221-linux-x64.tar.gz
    # mkdir /usr/java
    # tar axf jdk-8u221-linux-x64.tar.gz -C /usr/java/
    # cd /usr/java
    # ln -sv jdk1.8.0_221/ default
    # vim /etc/profile.d/java.sh
        export JAVA_HOME=/usr/java/default
        export PATH=${JAVA_HOME}/bin:${PATH}
    # source /etc/profile.d/java.sh
    # java -version
    ```

2. 下载zookeeper并解压至指定目录

    ```
    # wget -P /tmp http://192.168.3.195/Softwares/zookeeper/zookeeper-3.4.14.tar.gz
    # tar axf /tmp/zookeeper-3.4.14.tar.gz -C /usr/local/
    # cd /usr/local
    # ln -sv zookeeper-3.4.14/ zookeeper
    # mkdir /usr/local/zookeeper/{data,logs}
    # cp zookeeper/conf/{zoo_sample.cfg,zoo.cfg}
    ```

3. 修改集群内zookeeper的配置文件并运行zookeeper

**注意：zookeeper集群内的每个节点的id不能相同。**

    ```
    # vim zookeeper/conf/zoo.cfg
        dataDir=/usr/local/zookeeper/data
        dataLogDir=/usr/local/zookeeper/logs
        server.1=192.168.3.190:2888:3888
        server.2=192.168.3.191:2888:3888
        server.3=192.168.3.192:2888:3888
    # echo 1 > /usr/local/zookeeper/data/myid
    # cd /usr/local/zookeeper/bin/
    # ./zkServer.sh start
    # ./zkServer.sh status
    # vim ./bin/zkEnv.sh
        ZOO_LOG_DIR="/datas/zookeeper/logs"
        ZOO_LOG4J_PROP="INFO,ROLLINGFILE"
    # vim ../conf/log4j.properties
        zookeeper.root.logger=INFO, ROLLINGFILE
        zookeeper.log.dir=/datas/zookeeper/logs
        log4j.appender.ROLLINGFILE=org.apache.log4j.RollingFileAppender
    # vim /etc/systemd/system/zookeeper.service
        [Unit]
        Description=Zookeeper service
        After=network.target

        [Service]
        Type=forking
        Environment="PATH=/usr/java/default/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin,JAVA_HOME=/usr/java/default"
        User=root
        Group=root
        ExecStart=/usr/local/zookeeper/bin/zkServer.sh start /usr/local/zookeeper/conf/zoo.cfg
        ExecStop=/usr/local/zookeeper/bin/zkServer.sh stop /usr/local/zookeeper/conf/zoo.cfg
        ExecReload=/usr/local/zookeeper/bin/zkServer.sh restart /usr/local/zookeeper/conf/zoo.cfg

        [Install]
        WantedBy=multi-user.target
    ```

4. 下载kafka并解压至指定目录

    ```
    # wget -P /root http://192.168.3.195/Softwares/kafka/kafka_2.11-0.11.0.3.tgz
    # tar axf /root/kafka_2.11-0.11.0.3.tgz -C /usr/local
    # cd /usr/local
    # ln -sv kafka_2.11-0.11.0.3 kafka
    # mkdir kafka/data
    ```

5. 修改集群内kafka的配置文件并运行kafka

**注意：建议每个kafka的broker.id使用其ip地址的主机位。**

    ```
    # vim kafka/config/server.properties
        broker.id=0
        listeners=PLAINTEXT://192.168.3.190:9092
        advertised.listeners=PLAINTEXT://192.168.3.190:9092
        log.dirs=/usr/local/kafka/data
        zookeeper.connect=192.168.3.190:2181,192.168.3.191:2181,192.168.3.192:2181
        num.partitions=5
        log.retention.hours=24
        auto.create.topics.enable=true
        default.replication.factor=2
    # cd kafka
    # vim ./bin/kafka-run-class.sh
        LOG_DIR="/datas/kafka/logs"
    # ./bin/kafka-server-start.sh -daemon config/server.properties
    # jps
    ```
